{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tiktoken\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "import urllib.request\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import time\n",
        "\n",
        "# Setup device\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "torch.set_printoptions(sci_mode=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT-2 from Scratch: Implementation and Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of characters: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n"
          ]
        }
      ],
      "source": [
        "# Download and load the text corpus\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        "       \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        "       \"the-verdict.txt\")\n",
        "file_path = \"the-verdict.txt\"\n",
        "if not os.path.exists(file_path):\n",
        "    urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(f\"Total number of characters: {len(raw_text)}\")\n",
        "print(raw_text[:100])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of tokens: 5145\n",
            "Sample encoded tokens: [40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138, 257, 7026, 15632, 438, 2016]\n"
          ]
        }
      ],
      "source": [
        "# Initialize the tokenizer\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# Demonstrate tokenization\n",
        "encoded_text = tokenizer.encode(raw_text)\n",
        "print(f\"\\nTotal number of tokens: {len(encoded_text)}\")\n",
        "print(\"Sample encoded tokens:\", encoded_text[:15])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building the GPT Model Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Layer Normalization\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GELU Activation Function\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feed-Forward Network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multi-Head Causal Self-Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "        \n",
        "        # Apply causal mask\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "        \n",
        "        # Scale and apply softmax\n",
        "        attn_weights = torch.softmax(attn_scores / math.sqrt(self.head_dim), dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Reshape and project output\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "        return context_vec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformer Block\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add input\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add input\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Full GPT Model\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "        )\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_ids = torch.arange(seq_len, device=in_idx.device)\n",
        "        pos_embeds = self.pos_emb(pos_ids)\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Pretrained GPT-2 Weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model and Text Generation Configuration\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility functions for text generation\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    return torch.tensor(encoded).unsqueeze(0)\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    return tokenizer.decode(token_ids.squeeze(0).tolist())\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "        probas = torch.softmax(logits, dim=-1)\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "    return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        }
      ],
      "source": [
        "# Download and load GPT-2 weights\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        "       \"LLMs-from-scratch/main/ch05/\"\n",
        "       \"01_main-chapter-code/gpt_download.py\")\n",
        "filename = \"gpt_download.py\"\n",
        "if not os.path.exists(filename):\n",
        "    urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "from gpt_download import download_and_load_gpt2\n",
        "\n",
        "model_size = \"124M\"\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "\n",
        "# Tweak config to match pretrained model\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "}\n",
        "model_name = f\"gpt2-small ({model_size})\"\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])\n",
        "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to load weights into our model\n",
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "        q_b, k_b, v_b = np.split(params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(gpt.trf_blocks[b].att.out_proj.weight, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(gpt.trf_blocks[b].att.out_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(gpt.trf_blocks[b].ff.layers[0].weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(gpt.trf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(gpt.trf_blocks[b].ff.layers[2].weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(gpt.trf_blocks[b].ff.layers[2].bias, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(gpt.trf_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(gpt.trf_blocks[b].norm1.shift, params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(gpt.trf_blocks[b].norm2.scale, params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(gpt.trf_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Output:\n",
            "Every effort moves you forward.\n",
            "\n",
            "The first step is to understand the importance of your work\n"
          ]
        }
      ],
      "source": [
        "# Instantiate and test the loaded model\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(NEW_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "prompt = \"Every effort moves you\"\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(prompt, tokenizer).to(device),\n",
        "    max_new_tokens=15,\n",
        "    context_size=NEW_CONFIG[\"context_length\"]\n",
        ")\n",
        "print(\"Model Output:\")\n",
        "print(token_ids_to_text(token_ids, tokenizer))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine-Tuning for Spam Classification with LoRA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n",
            "\n",
            "Sample of training data:\n",
            "   Label                                               Text\n",
            "0      0                Dude how do you like the buff wind.\n",
            "1      0  Tessy..pls do me a favor. Pls convey my birthd...\n",
            "2      1  Reminder: You have not downloaded the content ...\n",
            "3      1  Got what it takes 2 take part in the WRC Rally...\n",
            "4      1  Shop till u Drop, IS IT YOU, either 10K, 5K, Â£...\n"
          ]
        }
      ],
      "source": [
        "# Preparing the Spam Dataset\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    print(\"Downloading spam dataset...\")\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    print(\"Extracting files...\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "    os.remove(zip_path)\n",
        "\n",
        "# Set up paths and URLs\n",
        "primary_url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "backup_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "# Execute the download with error handling\n",
        "try:\n",
        "    download_and_unzip_spam_data(primary_url, zip_path, extracted_path, data_file_path)\n",
        "except Exception as e:\n",
        "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
        "    download_and_unzip_spam_data(backup_url, zip_path, extracted_path, data_file_path)\n",
        "\n",
        "# Load, process, and split the data\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
        "\n",
        "# Create a balanced dataset\n",
        "num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "\n",
        "# Split and save datasets\n",
        "train_frac, val_frac = 0.7, 0.1\n",
        "df_shuffled = balanced_df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "train_end = int(len(df_shuffled) * train_frac)\n",
        "val_end = train_end + int(len(df_shuffled) * val_frac)\n",
        "train_df, val_df, test_df = df_shuffled[:train_end], df_shuffled[train_end:val_end], df_shuffled[val_end:]\n",
        "\n",
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "val_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)\n",
        "\n",
        "print(\"\\nSample of training data:\")\n",
        "print(train_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating a Custom Dataset and DataLoaders\n",
        "class SpamDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "        self.encoded_texts = [encoded[:self.max_length] for encoded in self.encoded_texts]\n",
        "        self.encoded_texts = [encoded + [pad_token_id] * (self.max_length - len(encoded)) for encoded in self.encoded_texts]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        label = self.data.iloc[index][\"Label\"]\n",
        "        return torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        return max(len(encoded) for encoded in self.encoded_texts)\n",
        "\n",
        "# Initialize datasets and dataloaders\n",
        "train_dataset = SpamDataset(csv_file=\"train.csv\", tokenizer=tokenizer)\n",
        "val_dataset = SpamDataset(csv_file=\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
        "test_dataset = SpamDataset(csv_file=\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=8, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=8, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=8, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implementing LoRA Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LoRALayer(torch.nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
        "        super().__init__()\n",
        "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
        "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
        "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.alpha * (x @ self.A @ self.B)\n",
        "\n",
        "class LinearWithLoRA(torch.nn.Module):\n",
        "    def __init__(self, linear, rank, alpha):\n",
        "        super().__init__()\n",
        "        self.linear = linear\n",
        "        self.lora = LoRALayer(linear.in_features, linear.out_features, rank, alpha)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x) + self.lora(x)\n",
        "\n",
        "def replace_linear_with_lora(model, rank, alpha):\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, nn.Linear):\n",
        "            # Do not replace the final classification head\n",
        "            if name != \"out_head\":\n",
        "                setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
        "        else:\n",
        "            replace_linear_with_lora(module, rank, alpha)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total trainable parameters with LoRA: 1,328,642\n"
          ]
        }
      ],
      "source": [
        "# Modifying the Model for Classification and Applying LoRA\n",
        "# Re-load a fresh pretrained model\n",
        "torch.manual_seed(123)\n",
        "model_lora = GPTModel(NEW_CONFIG)\n",
        "load_weights_into_gpt(model_lora, params)\n",
        "\n",
        "# Add a classification head\n",
        "num_classes = 2\n",
        "model_lora.out_head = torch.nn.Linear(in_features=NEW_CONFIG[\"emb_dim\"], out_features=num_classes)\n",
        "\n",
        "# Freeze original model parameters\n",
        "for param in model_lora.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# Apply LoRA and unfreeze LoRA and classification head parameters\n",
        "lora_rank = 8\n",
        "lora_alpha = 16\n",
        "replace_linear_with_lora(model_lora, rank=lora_rank, alpha=lora_alpha)\n",
        "\n",
        "# Unfreeze the new layers\n",
        "for param in model_lora.out_head.parameters():\n",
        "    param.requires_grad = True\n",
        "for name, param in model_lora.named_parameters():\n",
        "    if \"lora\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Move the ENTIRE modified model to the device at the end\n",
        "model_lora.to(device)\n",
        "        \n",
        "total_trainable_params = sum(p.numel() for p in model_lora.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters with LoRA: {total_trainable_params:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training the LoRA-adapted Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility functions for classification training\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # Use last token's output for classification\n",
        "    return torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "\n",
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "            if i >= num_batches:\n",
        "                break\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "            logits = model(input_batch)[:, -1, :]\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "    return correct_predictions / num_examples\n",
        "\n",
        "def evaluate_model_cls(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = np.mean([calc_loss_batch(X, y, model, device).item() for i, (X, y) in enumerate(train_loader) if i < eval_iter])\n",
        "        val_loss = np.mean([calc_loss_batch(X, y, model, device).item() for i, (X, y) in enumerate(val_loader) if i < eval_iter])\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            examples_seen += input_batch.shape[0]\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model_cls(model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "        \n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        \n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.028, Val loss 1.822\n",
            "Ep 1 (Step 000020): Train loss 0.573, Val loss 0.592\n",
            "Ep 1 (Step 000040): Train loss 0.358, Val loss 0.549\n",
            "Ep 1 (Step 000060): Train loss 0.315, Val loss 0.386\n",
            "Ep 1 (Step 000080): Train loss 0.623, Val loss 0.506\n",
            "Ep 1 (Step 000100): Train loss 0.348, Val loss 0.493\n",
            "Ep 1 (Step 000120): Train loss 0.152, Val loss 0.396\n",
            "Training accuracy: 97.50% | Validation accuracy: 87.50%\n",
            "Ep 2 (Step 000140): Train loss 0.555, Val loss 0.688\n",
            "Ep 2 (Step 000160): Train loss 0.240, Val loss 0.578\n",
            "Ep 2 (Step 000180): Train loss 0.204, Val loss 0.218\n",
            "Ep 2 (Step 000200): Train loss 0.164, Val loss 0.247\n",
            "Ep 2 (Step 000220): Train loss 0.070, Val loss 0.261\n",
            "Ep 2 (Step 000240): Train loss 0.279, Val loss 0.556\n",
            "Training accuracy: 90.00% | Validation accuracy: 87.50%\n",
            "Ep 3 (Step 000260): Train loss 0.152, Val loss 0.228\n",
            "Ep 3 (Step 000280): Train loss 0.132, Val loss 0.126\n",
            "Ep 3 (Step 000300): Train loss 0.198, Val loss 0.234\n",
            "Ep 3 (Step 000320): Train loss 0.073, Val loss 0.325\n",
            "Ep 3 (Step 000340): Train loss 0.068, Val loss 0.212\n",
            "Ep 3 (Step 000360): Train loss 0.061, Val loss 0.746\n",
            "Ep 3 (Step 000380): Train loss 0.223, Val loss 0.821\n",
            "Training accuracy: 100.00% | Validation accuracy: 95.00%\n"
          ]
        }
      ],
      "source": [
        "# Run the training\n",
        "torch.manual_seed(123)\n",
        "optimizer = torch.optim.AdamW(model_lora.parameters(), lr=5e-5, weight_decay=0.01)\n",
        "num_epochs = 3\n",
        "\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model_lora, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=20, eval_iter=5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating the Fine-Tuned Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "    ax2 = ax1.twiny()\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses, label=\"loss\")\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 96.33%\n",
            "'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.' is classified as: spam\n",
            "'Hey, just wanted to check if we're still on for dinner tonight? Let me know!' is classified as: not spam\n"
          ]
        }
      ],
      "source": [
        "# Final evaluation on the test set\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model_lora, device)\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n",
        "\n",
        "# Example classification\n",
        "def classify_review(text, model, tokenizer, device, max_length, pad_token_id=50256):\n",
        "    model.eval()\n",
        "    encoded = tokenizer.encode(text)\n",
        "    encoded = encoded[:max_length]\n",
        "    encoded += [pad_token_id] * (max_length - len(encoded))\n",
        "    input_tensor = torch.tensor(encoded, device=device).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[:, -1, :]\n",
        "        predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "    return \"spam\" if predicted_label == 1 else \"not spam\"\n",
        "\n",
        "text_1 = \"You are a winner you have been specially selected to receive $1000 cash or a $2000 award.\"\n",
        "text_2 = \"Hey, just wanted to check if we're still on for dinner tonight? Let me know!\"\n",
        "\n",
        "print(f\"'{text_1}' is classified as: {classify_review(text_1, model_lora, tokenizer, device, train_dataset.max_length)}\")\n",
        "print(f\"'{text_2}' is classified as: {classify_review(text_2, model_lora, tokenizer, device, train_dataset.max_length)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instruction Fine-Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample formatted prompt:\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n"
          ]
        }
      ],
      "source": [
        "# Preparing the Instruction Dataset\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/\"\n",
        "       \"main/ch07/01_main-chapter-code/instruction-data.json\")\n",
        "if not os.path.exists(file_path):\n",
        "    urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "    instruction_data = json.load(file)\n",
        "\n",
        "# Split the data\n",
        "train_portion = int(len(instruction_data) * 0.85)\n",
        "test_portion = int(len(instruction_data) * 0.1)\n",
        "train_data_instr = instruction_data[:train_portion]\n",
        "test_data_instr = instruction_data[train_portion : train_portion + test_portion]\n",
        "val_data_instr = instruction_data[train_portion + test_portion :]\n",
        "\n",
        "# Prompt formatting function\n",
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "    return instruction_text + input_text\n",
        "\n",
        "print(\"Sample formatted prompt:\")\n",
        "print(format_input(instruction_data[50]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Data Handling for Instruction Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instruction Dataset and Custom Collate Function\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100):\n",
        "    # Find the length of the longest sequence in the batch\n",
        "    batch_max_length = max(len(item) + 1 for item in batch)\n",
        "    \n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        # Create a new list with an added padding token at the end\n",
        "        new_item = item.copy()\n",
        "        new_item.append(pad_token_id)\n",
        "        \n",
        "        # Pad the new item to the max length of the batch\n",
        "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
        "        \n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        targets = torch.tensor(padded[1:])\n",
        "        \n",
        "        # Mask out the padding tokens in the targets\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "        \n",
        "    inputs_tensor = torch.stack(inputs_lst)\n",
        "    targets_tensor = torch.stack(targets_lst)\n",
        "    return inputs_tensor, targets_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating DataLoaders\n",
        "from functools import partial\n",
        "\n",
        "customized_collate_fn = partial(custom_collate_fn)\n",
        "\n",
        "train_dataset_instr = InstructionDataset(train_data_instr, tokenizer)\n",
        "train_loader_instr = DataLoader(\n",
        "    train_dataset_instr, batch_size=4, collate_fn=customized_collate_fn, shuffle=True, drop_last=True\n",
        ")\n",
        "val_dataset_instr = InstructionDataset(val_data_instr, tokenizer)\n",
        "val_loader_instr = DataLoader(\n",
        "    val_dataset_instr, batch_size=4, collate_fn=customized_collate_fn, shuffle=False\n",
        ")\n",
        "test_dataset_instr = InstructionDataset(test_data_instr, tokenizer)\n",
        "test_loader_instr = DataLoader(\n",
        "    test_dataset_instr, batch_size=4, collate_fn=customized_collate_fn, shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fine-Tuning the GPT-2 Medium Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 1024)\n",
              "  (pos_emb): Embedding(1024, 1024)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (12): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (13): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (14): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (15): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (16): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (17): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (18): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (19): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (20): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (21): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (22): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (23): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load GPT-2 Medium (355M)\n",
        "model_size_medium = \"355M\"\n",
        "settings_medium, params_medium = download_and_load_gpt2(model_size=model_size_medium, models_dir=\"gpt2\")\n",
        "\n",
        "model_configs_medium = {\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16}}\n",
        "CHOOSE_MODEL_MEDIUM = \"gpt2-medium (355M)\"\n",
        "BASE_CONFIG_MEDIUM = GPT_CONFIG_124M.copy() # Start with base and update\n",
        "BASE_CONFIG_MEDIUM.update(model_configs_medium[CHOOSE_MODEL_MEDIUM])\n",
        "BASE_CONFIG_MEDIUM.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
        "\n",
        "model_instr = GPTModel(BASE_CONFIG_MEDIUM)\n",
        "load_weights_into_gpt(model_instr, params_medium)\n",
        "model_instr.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training and Loss Functions for Language Modeling\n",
        "def calc_loss_batch_language_modeling(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(\n",
        "        logits.view(-1, logits.size(-1)), \n",
        "        target_batch.view(-1)\n",
        "    )\n",
        "    return loss\n",
        "\n",
        "def calc_loss_loader_instr(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    with torch.no_grad():\n",
        "        for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "            if i >= num_batches:\n",
        "                break\n",
        "            loss = calc_loss_batch_language_modeling(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def train_model_simple_instr(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, tokenizer):\n",
        "    train_losses, val_losses = [], []\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for i, (input_batch, target_batch) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}\")):\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch_language_modeling(input_batch, target_batch, model, device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Evaluation\n",
        "            if i > 0 and i % eval_freq == 0:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    train_loss = calc_loss_loader_instr(train_loader, model, device, num_batches=eval_iter)\n",
        "                    val_loss = calc_loss_loader_instr(val_loader, model, device, num_batches=eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Epoch {epoch+1}, Step {i}: Train Loss {train_loss:.3f}, Val Loss {val_loss:.3f}\")\n",
        "                model.train()\n",
        "    return train_losses, val_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  43%|âââââ     | 101/233 [00:50<01:59,  1.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Step 100: Train Loss 0.598, Val Loss 0.788\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  86%|âââââââââ | 201/233 [01:29<00:24,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Step 200: Train Loss 0.594, Val Loss 0.679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|ââââââââââ| 233/233 [01:42<00:00,  2.27it/s]\n",
            "Epoch 2:  43%|âââââ     | 101/233 [00:41<01:50,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Step 100: Train Loss 0.393, Val Loss 0.671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  86%|âââââââââ | 201/233 [01:22<00:26,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Step 200: Train Loss 0.361, Val Loss 0.658\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|ââââââââââ| 233/233 [01:34<00:00,  2.46it/s]\n"
          ]
        }
      ],
      "source": [
        "# Run instruction fine-tuning\n",
        "torch.manual_seed(123)\n",
        "optimizer = torch.optim.AdamW(model_instr.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "num_epochs = 2 # Using 2 epochs for demonstration\n",
        "\n",
        "train_losses, val_losses = train_model_simple_instr(\n",
        "    model_instr, train_loader_instr, val_loader_instr, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=100, eval_iter=10, tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "torch.save(model_instr.state_dict(), \"gpt2-medium-sft.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating with LLM-as-a-Judge\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|ââââââââââ| 110/110 [02:04<00:00,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated response for the first test sample:\n",
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a cheetah.'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate responses for the test set\n",
        "model_instr.eval()\n",
        "test_data_with_responses = test_data_instr.copy()\n",
        "\n",
        "# Advanced text generation function with temperature and top-k\n",
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        if top_k is not None:\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1].unsqueeze(-1)\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
        "        \n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "            \n",
        "        if eos_id is not None and idx_next.item() == eos_id:\n",
        "            break\n",
        "            \n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "    return idx\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data_with_responses), total=len(test_data_with_responses)):\n",
        "    input_text = format_input(entry)\n",
        "    token_ids = generate(\n",
        "        model=model_instr,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG_MEDIUM[\"context_length\"],\n",
        "        eos_id=50256 # <|endoftext|>\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "    test_data_with_responses[i][\"model_response\"] = response_text\n",
        "\n",
        "with open(\"instruction-data-with-response.json\", \"w\") as f:\n",
        "    json.dump(test_data_with_responses, f, indent=4)\n",
        "    \n",
        "print(\"\\nGenerated response for the first test sample:\")\n",
        "print(test_data_with_responses[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scoring Responses with Llama 3 via Ollama\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ollama is running.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring entries: 100%|ââââââââââ| 110/110 [00:53<00:00,  2.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Number of scores collected: 110 of 110\n",
            "Average score: 43.05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "\n",
        "# Check if Ollama is running\n",
        "def check_if_running(process_name):\n",
        "    return any(process_name in proc.info[\"name\"] for proc in psutil.process_iter([\"name\"]))\n",
        "\n",
        "if not check_if_running(\"ollama\"):\n",
        "    print(\"Ollama is not running. Please start it to proceed with evaluation.\")\n",
        "else:\n",
        "    print(\"Ollama is running.\")\n",
        "\n",
        "def query_model(prompt, model=\"llama3\", url=\"http://localhost:11434/api/generate\"):\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"prompt\": prompt,\n",
        "        \"stream\": False,\n",
        "        \"options\": {\"seed\": 123, \"temperature\": 0}\n",
        "    }\n",
        "    payload = json.dumps(data).encode(\"utf-8\")\n",
        "    request = urllib.request.Request(url, data=payload, method=\"POST\")\n",
        "    request.add_header(\"Content-Type\", \"application/json\")\n",
        "    \n",
        "    with urllib.request.urlopen(request) as response:\n",
        "        response_data = json.loads(response.read().decode(\"utf-8\"))\n",
        "        return response_data.get(\"response\", \"\").strip()\n",
        "\n",
        "# Function to automate scoring\n",
        "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
        "    scores = []\n",
        "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
        "        prompt = (\n",
        "            f\"Given the instruction `{entry['instruction']}` and input `{entry['input']}`, \"\n",
        "            f\"and the correct output `{entry['output']}`, \"\n",
        "            f\"score the model's generated response `{entry[json_key]}`\"\n",
        "            f\" on a scale from 0 to 100, where 100 is a perfect response. \"\n",
        "            f\"Respond with only the integer score.\"\n",
        "        )\n",
        "        score_str = query_model(prompt, model)\n",
        "        try:\n",
        "            score = int(re.search(r'\\d+', score_str).group()) # Extract first number\n",
        "            scores.append(score)\n",
        "        except (ValueError, AttributeError):\n",
        "            print(f\"Could not parse score from response: '{score_str}'\")\n",
        "            continue\n",
        "    return scores\n",
        "\n",
        "# Run the evaluation if Ollama is active\n",
        "if check_if_running(\"ollama\"):\n",
        "    scores = generate_model_scores(test_data_with_responses, \"model_response\")\n",
        "    if scores:\n",
        "        print(f\"\\nNumber of scores collected: {len(scores)} of {len(test_data_with_responses)}\")\n",
        "        print(f\"Average score: {sum(scores)/len(scores):.2f}\")\n",
        "else:\n",
        "    print(\"Skipping evaluation as Ollama is not running.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llms",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
